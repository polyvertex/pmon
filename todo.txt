

#-------------------------------------------------------------------------------
# Useful SQL requests
#-------------------------------------------------------------------------------
# list the number of different known keys
SELECT la.key
FROM logatom AS la
GROUP BY la.key
ORDER BY la.key ASC;

# see which keys flood the database
SELECT la.key, COUNT(la.key) AS cnt
FROM logatom AS la
GROUP BY la.key
ORDER BY cnt DESC, la.key ASC;

# see returned status from agents
SELECT la.machine_id, m.name AS machine_name, la.unix_first, la.unix_last, la.value AS status
FROM logatom AS la, machine AS m
WHERE la.key='agent.status'
AND m.id = la.machine_id
ORDER BY la.machine_id ASC, la.id ASC;

# see the total duration of the database in seconds and in days
SELECT
    (MAX(la.unix_last) - MIN(la.unix_first)) AS seconds,
    ((MAX(la.unix_last) - MIN(la.unix_first)) / 86400) AS days
FROM logatom AS la;

# count the number of different known keys for each machine
# this allows us to setup the Daemon::Db::MAX_KEYS_CACHED constant properly
SELECT la.machine_id, COUNT(DISTINCT la.key) AS distinct_keys
FROM logatom AS la
GROUP BY la.machine_id
ORDER BY la.machine_id ASC;


#-------------------------------------------------------------------------------
# Old TODO, features overview
#-------------------------------------------------------------------------------
* séparation client / serveur (i.e.: agent / daemon)
  * client :
    * récupération puis envoi minimal des données
    * envoi atomique des données (à la fin du process de récup)
    * gestion des pb de connexion :
      timeout ? essais ? on s'en fout (vu qu'on lance le client toutes les minutes) ?
  * serveur : gestion des bases, gestion des sous-bases (rrdtool), affichage
  -> mais où mettre le serveur !!!
* proposer une option pour maj TOUTES les infos (pour first-time, short-uptime ou reinstall)
* selon le type de données, il faut :
  * conserver TOUT l'historique
  * conserver un historique limité (en jours OU en nombre de remontées)
* si uptime < 15 minutes, maj TOUTES les données
* les sub-scripts doivent être lancés selon des pools de priorité par exemple :
  connections != ping
* données à afficher :
  * uptime
  * distrib + version
  * kernel + version
  * cpu info (name, frequency, cache, cores)
  * cpu usage (?)
  * cpu load
  * mem usage (phys, swap, total)
  * processes (?)
  * logged-in users
  * disks space (each)
  * disks temperature
  * network traffic (each, total)
  * network (listen, established count)
  * dir size
  -
  * ping (google, free)
  * bind (queries/hour)
  * apache (hits/hour, bytes/seconds)
  * lighttpd (hits/hour, bytes/seconds)
  * postfix queue
  * dovecot connections
  * mysql
